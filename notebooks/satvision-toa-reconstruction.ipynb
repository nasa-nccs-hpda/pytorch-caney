{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ab2075-c488-46b9-8cd2-0cdaf399acfc",
   "metadata": {},
   "source": [
    "# Satvision-TOA Reconstruction Notebook\n",
    "\n",
    "Version: 02.20.24\n",
    "\n",
    "Env: `Python [conda env:ilab-pytorch]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e88ea70-7dbf-4b67-a12d-db36e2bc9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yacs timm segmentation-models-pytorch termcolor webdataset==0.2.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046c3e5-c458-4e03-9c96-e9eb95a04963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7db1bc-09ee-47e3-9015-e6b148d497e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../pytorch-caney')\n",
    "\n",
    "from pytorch_caney.config import get_config\n",
    "\n",
    "from pytorch_caney.training.mim_utils import load_checkpoint, load_pretrained\n",
    "\n",
    "from pytorch_caney.models.build import build_model\n",
    "\n",
    "from pytorch_caney.ptc_logging import create_logger\n",
    "\n",
    "from pytorch_caney.data.datamodules import mim_webdataset_datamodule\n",
    "\n",
    "from pytorch_caney.data.transforms import SimmimTransform, SimmimMaskGenerator\n",
    "\n",
    "from pytorch_caney.config import _C, _update_config_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841e464-f880-4e53-bf31-f9f225713918",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6274e323-bc04-41d4-bc49-baed65d027e6",
   "metadata": {},
   "source": [
    "### Clone model ckpt from huggingface\n",
    "\n",
    "```bash\n",
    "# On prism/explore\n",
    "module load git-lfs\n",
    "\n",
    "git lfs install\n",
    "\n",
    "git clone git@hf.co:nasa-cisto-data-science-group/satvision-toa-base\n",
    "```\n",
    "\n",
    "Note: If using git w/ ssh, make sure you have ssh keys enabled to clone using ssh auth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af699ba3-2d98-4daf-9437-c322d7b59a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH: str = '../../satvision-toa-base/satvision-toa_84M_2M_100.pth'\n",
    "CONFIG_PATH: str = '../../satvision-toa-base/mim_pretrain_swinv2_satvision-toa_base_192_window12_800ep.yaml'\n",
    "\n",
    "BATCH_SIZE: int = 64 # Want to report loss on every image? Change to 1.\n",
    "OUTPUT: str = '.'\n",
    "TAG: str = 'satvision-base-toa-reconstruction'\n",
    "DATA_PATH: str = '/explore/nobackup/projects/ilab/projects/3DClouds/data/mosaic-v3/webdatasets'\n",
    "DATA_PATHS: list = [DATA_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4593e8c-6e94-4d01-b86e-5b78b621fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update config given configurations\n",
    "\n",
    "config = _C.clone()\n",
    "_update_config_from_file(config, CONFIG_PATH)\n",
    "\n",
    "config.defrost()\n",
    "config.MODEL.RESUME = MODEL_PATH\n",
    "config.DATA.DATA_PATHS = DATA_PATHS\n",
    "config.DATA.BATCH_SIZE = BATCH_SIZE\n",
    "config.OUTPUT = OUTPUT\n",
    "config.TAG = TAG\n",
    "config.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a4474-88e4-44d5-b899-7aaf6cbed6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='app.log',  # Specify the log file name\n",
    "    level=logging.INFO,  # Set logging level to DEBUG\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',  # Specify log message format\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'  # Specify date format\n",
    ")\n",
    "\n",
    "# Add logging to standard output\n",
    "console = logging.StreamHandler()  # Create a handler for standard output\n",
    "console.setLevel(logging.INFO)  # Set logging level for standard output\n",
    "console.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))  # Set log message format for standard output\n",
    "logger = logging.getLogger('')\n",
    "logger.addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abf348-c6bf-43a3-b00a-cc5f8d80545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(MODEL_PATH)\n",
    "model = build_model(config, pretrain=True)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"number of params: {n_parameters}\")\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ba52e-62ca-4800-b2aa-deaaea64be9f",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c52c66-f322-413c-be76-6c7abfd159bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = mim_webdataset_datamodule.build_mim_dataloader(config, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acf5e9-eb2a-496c-baa6-3b74503a2978",
   "metadata": {},
   "source": [
    "## Prediction helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595336f8-71b4-418b-b153-2461583ed613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, num_batches=5):\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    masks = []\n",
    "    losses = []\n",
    "\n",
    "    for idx, img_mask in enumerate(dataloader):\n",
    "        \n",
    "        if idx > num_batches:\n",
    "            return inputs, outputs, masks, losses\n",
    "\n",
    "        img_mask = img_mask[0]\n",
    "\n",
    "        img = torch.stack([pair[0] for pair in img_mask])\n",
    "        mask = torch.stack([pair[1] for pair in img_mask])\n",
    "\n",
    "        img = img.cuda(non_blocking=True)\n",
    "        mask = mask.cuda(non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with amp.autocast(enabled=config.ENABLE_AMP):\n",
    "                z = model.encoder(img, mask)\n",
    "                img_recon = model.decoder(z)\n",
    "                loss = model(img, mask)\n",
    "\n",
    "        inputs.extend(img.cpu())\n",
    "        masks.extend(mask.cpu())\n",
    "        outputs.extend(img_recon.cpu())\n",
    "        losses.append(losses)\n",
    "    \n",
    "    return inputs, outputs, masks, losses\n",
    "\n",
    "\n",
    "def minmax_norm(img_arr):\n",
    "    arr_min = img_arr.min()\n",
    "    arr_max = img_arr.max()\n",
    "    img_arr_scaled = (img_arr - arr_min) / (arr_max - arr_min)\n",
    "    img_arr_scaled = img_arr_scaled * 255\n",
    "    img_arr_scaled = img_arr_scaled.astype(np.uint8)\n",
    "    return img_arr_scaled\n",
    "\n",
    "\n",
    "def process_mask(mask):\n",
    "    mask = mask.unsqueeze(0)\n",
    "    mask = mask.repeat_interleave(4, 1).repeat_interleave(4, 2).unsqueeze(1).contiguous()\n",
    "    mask = mask[0, 0, :, :]\n",
    "    mask = np.stack([mask, mask, mask], axis=-1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def process_prediction(image, img_recon, mask, rgb_index):\n",
    "    img_normed = minmax_norm(image.numpy())\n",
    "\n",
    "    mask = process_mask(mask)\n",
    "    \n",
    "    red_idx = rgb_index[0]\n",
    "    blue_idx = rgb_index[1]\n",
    "    green_idx = rgb_index[2]\n",
    "\n",
    "    rgb_image = np.stack((img_normed[red_idx, :, :],\n",
    "                        img_normed[blue_idx, :, :],\n",
    "                        img_normed[green_idx, :, :]),\n",
    "                        axis=-1)\n",
    "\n",
    "    img_recon = minmax_norm(img_recon.numpy())\n",
    "    rgb_image_recon = np.stack((img_recon[red_idx, :, :],\n",
    "                                img_recon[blue_idx, :, :],\n",
    "                                img_recon[green_idx, :, :]),\n",
    "                                axis=-1)\n",
    "\n",
    "    rgb_masked = np.where(mask == 0, rgb_image, rgb_image_recon)\n",
    "    rgb_image_masked = np.where(mask == 1, 0, rgb_image)\n",
    "    rgb_recon_masked = rgb_masked\n",
    "    \n",
    "    return rgb_image, rgb_image_masked, rgb_recon_masked, mask\n",
    "\n",
    "\n",
    "def plot_export_pdf(path, num_sample, inputs, outputs, masks, rgb_index):\n",
    "    random_subsample = random.sample(range(len(inputs)), num_sample)\n",
    "    pdf_plot_obj = PdfPages(path)\n",
    "\n",
    "    for idx in random_subsample:\n",
    "        # prediction processing\n",
    "        image = inputs[idx]\n",
    "        img_recon = outputs[idx]\n",
    "        mask = masks[idx]\n",
    "        rgb_image, rgb_image_masked, rgb_recon_masked, mask = \\\n",
    "            process_prediction(image, img_recon, mask, rgb_index)\n",
    "\n",
    "        # matplotlib code\n",
    "        fig, (ax01, ax23) = plt.subplots(2, 2, figsize=(40, 30))\n",
    "        ax0, ax1 = ax01\n",
    "        ax2, ax3 = ax23\n",
    "        ax2.imshow(rgb_image)\n",
    "        ax2.set_title(f\"Idx: {idx} MOD021KM v6.1 Bands: {rgb_index}\")\n",
    "\n",
    "        ax0.imshow(rgb_recon_masked)\n",
    "        ax0.set_title(f\"Idx: {idx} Model reconstruction\")\n",
    "\n",
    "        ax1.imshow(rgb_image_masked)\n",
    "        ax1.set_title(f\"Idx: {idx} MOD021KM Bands: {rgb_index}, masked\")\n",
    "        \n",
    "        ax3.matshow(mask[:, :, 0])\n",
    "        ax3.set_title(f\"Idx: {idx} Reconstruction Mask\")\n",
    "        pdf_plot_obj.savefig()\n",
    "\n",
    "    pdf_plot_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c44b5-6d88-45c4-b397-c38de8064544",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43bfaf-6379-43d5-9be3-bd0e55f5ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "inputs, outputs, masks, losses = predict(model, dataloader, num_batches=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3f102c-94df-4d9e-8040-52197a7e71db",
   "metadata": {},
   "source": [
    "## Plot and write to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebdcd1d-09db-4ccf-8cc1-58d6f47e3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '../../satvision-toa-reconstruction-pdf-02.20.pdf'\n",
    "num_samples = 10 # Number of random samples from the predictions\n",
    "rgb_index = [0, 3, 2] # Indices of [Red band, Blue band, Green band]\n",
    "\n",
    "plot_export_pdf(pdf_path, num_samples, inputs, outputs, masks, rgb_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a57f4d-5df0-47a3-bfb6-d7f29a95e276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ilab-pytorch]",
   "language": "python",
   "name": "conda-env-ilab-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
