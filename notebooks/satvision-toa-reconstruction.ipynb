{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ab2075-c488-46b9-8cd2-0cdaf399acfc",
   "metadata": {},
   "source": [
    "# Satvision-TOA Reconstruction Notebook\n",
    "\n",
    "Version: 03.15.24\n",
    "\n",
    "Env: `Python [conda env:ilab-pytorch]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e88ea70-7dbf-4b67-a12d-db36e2bc9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yacs timm segmentation-models-pytorch termcolor webdataset==0.2.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046c3e5-c458-4e03-9c96-e9eb95a04963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7db1bc-09ee-47e3-9015-e6b148d497e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../pytorch-caney')\n",
    "\n",
    "from pytorch_caney.config import get_config\n",
    "\n",
    "from pytorch_caney.models.build import build_model\n",
    "\n",
    "from pytorch_caney.ptc_logging import create_logger\n",
    "\n",
    "from pytorch_caney.data.datasets.mim_modis_22m_dataset import MODIS22MDataset\n",
    "\n",
    "from pytorch_caney.data.transforms import SimmimTransform, SimmimMaskGenerator\n",
    "\n",
    "from pytorch_caney.config import _C, _update_config_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841e464-f880-4e53-bf31-f9f225713918",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6274e323-bc04-41d4-bc49-baed65d027e6",
   "metadata": {},
   "source": [
    "### Clone model ckpt from huggingface\n",
    "\n",
    "```bash\n",
    "# On prism/explore\n",
    "module load git-lfs\n",
    "\n",
    "git lfs install\n",
    "\n",
    "git clone git@hf.co:nasa-cisto-data-science-group/satvision-toa-huge\n",
    "```\n",
    "\n",
    "Note: If using git w/ ssh, make sure you have ssh keys enabled to clone using ssh auth. \n",
    "\n",
    "If experiencing ssh-related authentication issues:\n",
    "```bash\n",
    "eval `ssh-agent -s` # starts ssh-agent\n",
    "\n",
    "ssh-add -l # is your ssh key added to the agent?\n",
    "\n",
    "ssh-add ~/.ssh/id_xxxx # adds ssh ID to ssh-agent\n",
    "\n",
    "ssh -T git@hf.co # Should return \"Hi <user-id>, welcome to Hugging Face.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af699ba3-2d98-4daf-9437-c322d7b59a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH: str = '/explore/nobackup/people/cssprad1/projects/satvision-toa/models/huge-16-224/mp_rank_00_model_states.pt'\n",
    "CONFIG_PATH: str = '/explore/nobackup/people/cssprad1/projects/satvision-toa/models/huge-16-224/mim_pretrain_swinv2_satvision_huge_224_patch16_100ep_lr3e4.yaml'\n",
    "\n",
    "BATCH_SIZE: int = 64 # Want to report loss on every image? Change to 1.\n",
    "OUTPUT: str = '.'\n",
    "TAG: str = 'satvision-base-toa-reconstruction'\n",
    "DATA_PATH: str = '/explore/nobackup/projects/ilab/projects/3DClouds/data/mosaic-v3/webdatasets'\n",
    "DATA_PATHS: list = [DATA_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4593e8c-6e94-4d01-b86e-5b78b621fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update config given configurations\n",
    "\n",
    "config = _C.clone()\n",
    "_update_config_from_file(config, CONFIG_PATH)\n",
    "\n",
    "config.defrost()\n",
    "config.MODEL.RESUME = MODEL_PATH\n",
    "config.DATA.DATA_PATHS = DATA_PATHS\n",
    "config.DATA.BATCH_SIZE = BATCH_SIZE\n",
    "config.OUTPUT = OUTPUT\n",
    "config.TAG = TAG\n",
    "config.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a4474-88e4-44d5-b899-7aaf6cbed6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='app.log',  # Specify the log file name\n",
    "    level=logging.INFO,  # Set logging level to DEBUG\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',  # Specify log message format\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'  # Specify date format\n",
    ")\n",
    "\n",
    "# Add logging to standard output\n",
    "console = logging.StreamHandler()  # Create a handler for standard output\n",
    "console.setLevel(logging.INFO)  # Set logging level for standard output\n",
    "console.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))  # Set log message format for standard output\n",
    "logger = logging.getLogger('')\n",
    "logger.addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abf348-c6bf-43a3-b00a-cc5f8d80545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(MODEL_PATH)\n",
    "model = build_model(config, pretrain=True)\n",
    "model.load_state_dict(checkpoint['module'])\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"number of params: {n_parameters}\")\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ba52e-62ca-4800-b2aa-deaaea64be9f",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8e300-3519-4be7-a478-7f0508d1d585",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = '/explore/nobackup/people/cssprad1/projects/satvision-toa/data/sampleModisToa2m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef13ad-90d6-4079-af70-6b6bb53f5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2ccf30-dfdd-4fff-8b95-3301105e1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBatchApply(idx, outputDir, regex, transform, model):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    masks = []\n",
    "    losses = []\n",
    "\n",
    "    batches = glob.glob(os.path.join(outputDir, regex))\n",
    "    print(batches)\n",
    "    print(f'Found {len(batches)}')\n",
    "\n",
    "    batchPath = batches[idx]\n",
    "    print(batchPath)\n",
    "    batch = np.load(batchPath)\n",
    "\n",
    "    imgMasks = [transform(img) for img in batch]\n",
    "\n",
    "    img = torch.stack([imgMask[0] for imgMask in imgMasks])\n",
    "    mask = torch.stack([torch.from_numpy(imgMask[1]) for imgMask in imgMasks])\n",
    "\n",
    "    img = img.cuda(non_blocking=True)\n",
    "    mask = mask.cuda(non_blocking=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with amp.autocast(enabled=config.ENABLE_AMP):\n",
    "            z = model.encoder(img, mask)\n",
    "            img_recon = model.decoder(z)\n",
    "            loss = model(img, mask)\n",
    "\n",
    "    inputs.extend(img.cpu())\n",
    "    masks.extend(mask.cpu())\n",
    "    outputs.extend(img_recon.cpu())\n",
    "    losses.append(loss.cpu())\n",
    "\n",
    "    return inputs, outputs, masks, losses  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acf5e9-eb2a-496c-baa6-3b74503a2978",
   "metadata": {},
   "source": [
    "## Prediction helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595336f8-71b4-418b-b153-2461583ed613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, num_batches=5):\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    masks = []\n",
    "    losses = []\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "\n",
    "        for idx, img_mask in enumerate(dataloader):\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "            if idx > num_batches:\n",
    "                return inputs, outputs, masks, losses\n",
    "\n",
    "            img_mask = img_mask[0]\n",
    "\n",
    "            img = torch.stack([pair[0] for pair in img_mask])\n",
    "            mask = torch.stack([pair[1] for pair in img_mask])\n",
    "\n",
    "            img = img.cuda(non_blocking=True)\n",
    "            mask = mask.cuda(non_blocking=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with amp.autocast(enabled=config.ENABLE_AMP):\n",
    "                    z = model.encoder(img, mask)\n",
    "                    img_recon = model.decoder(z)\n",
    "                    loss = model(img, mask)\n",
    "\n",
    "            inputs.extend(img.cpu())\n",
    "            masks.extend(mask.cpu())\n",
    "            outputs.extend(img_recon.cpu())\n",
    "            losses.append(loss.cpu())\n",
    "    \n",
    "    return inputs, outputs, masks, losses\n",
    "\n",
    "\n",
    "def minmax_norm(img_arr):\n",
    "    arr_min = img_arr.min()\n",
    "    arr_max = img_arr.max()\n",
    "    img_arr_scaled = (img_arr - arr_min) / (arr_max - arr_min)\n",
    "    img_arr_scaled = img_arr_scaled * 255\n",
    "    img_arr_scaled = img_arr_scaled.astype(np.uint8)\n",
    "    return img_arr_scaled\n",
    "\n",
    "\n",
    "def process_mask(mask):\n",
    "    mask = mask.unsqueeze(0)\n",
    "    mask = mask.repeat_interleave(4, 1).repeat_interleave(4, 2).unsqueeze(1).contiguous()\n",
    "    mask = mask[0, 0, :, :]\n",
    "    mask = np.stack([mask, mask, mask], axis=-1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def process_prediction(image, img_recon, mask, rgb_index):\n",
    "\n",
    "    mask = process_mask(mask)\n",
    "    \n",
    "    red_idx = rgb_index[0]\n",
    "    blue_idx = rgb_index[1]\n",
    "    green_idx = rgb_index[2]\n",
    "\n",
    "    image = image.numpy()\n",
    "    rgb_image = np.stack((image[red_idx, :, :],\n",
    "                          image[blue_idx, :, :],\n",
    "                          image[green_idx, :, :]),\n",
    "                         axis=-1)\n",
    "    rgb_image = minmax_norm(rgb_image)\n",
    "\n",
    "    img_recon = img_recon.numpy()\n",
    "    rgb_image_recon = np.stack((img_recon[red_idx, :, :],\n",
    "                                img_recon[blue_idx, :, :],\n",
    "                                img_recon[green_idx, :, :]),\n",
    "                                axis=-1)\n",
    "    rgb_image_recon = minmax_norm(rgb_image_recon)\n",
    "\n",
    "    rgb_masked = np.where(mask == 0, rgb_image, rgb_image_recon)\n",
    "    rgb_image_masked = np.where(mask == 1, 0, rgb_image)\n",
    "    rgb_recon_masked = rgb_masked\n",
    "    \n",
    "    return rgb_image, rgb_image_masked, rgb_recon_masked, mask\n",
    "\n",
    "\n",
    "def plot_export_pdf(path, num_sample, inputs, outputs, masks, rgb_index):\n",
    "    random_subsample = list(random.sample(range(len(inputs)), num_sample))\n",
    "    pdf_plot_obj = PdfPages(path)\n",
    "\n",
    "    for idx in random_subsample:\n",
    "        # prediction processing\n",
    "        image = inputs[idx]\n",
    "        img_recon = outputs[idx]\n",
    "        mask = masks[idx]\n",
    "        rgb_image, rgb_image_masked, rgb_recon_masked, mask = \\\n",
    "            process_prediction(image, img_recon, mask, rgb_index)\n",
    "\n",
    "        # matplotlib code\n",
    "        fig, (ax01, ax23) = plt.subplots(2, 2, figsize=(40, 30))\n",
    "        ax0, ax1 = ax01\n",
    "        ax2, ax3 = ax23\n",
    "        ax2.imshow(rgb_image)\n",
    "        ax2.set_title(f\"Idx: {idx} MOD021KM v6.1 Bands: {rgb_index}\")\n",
    "\n",
    "        ax0.imshow(rgb_recon_masked)\n",
    "        ax0.set_title(f\"Idx: {idx} Model reconstruction\")\n",
    "\n",
    "        ax1.imshow(rgb_image_masked)\n",
    "        ax1.set_title(f\"Idx: {idx} MOD021KM Bands: {rgb_index}, masked\")\n",
    "        \n",
    "        ax3.matshow(mask[:, :, 0])\n",
    "        ax3.set_title(f\"Idx: {idx} Reconstruction Mask\")\n",
    "        pdf_plot_obj.savefig()\n",
    "\n",
    "    pdf_plot_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c44b5-6d88-45c4-b397-c38de8064544",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3f102c-94df-4d9e-8040-52197a7e71db",
   "metadata": {},
   "source": [
    "## Plot and write to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebdcd1d-09db-4ccf-8cc1-58d6f47e3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_index = [0, 2, 1] # Indices of [Red band, Blue band, Green band]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1859b82-98fa-4637-813e-763ca71ae9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedBatches = {\n",
    "    0: [58, 24, 17, 2, 48, 29, 41, 18, 55, 23, 43, 61, 40, 7, 63, 16],\n",
    "    1: [47, 24, 50, 30, 2, 44, 21, 36, 13, 40, 46, 53, 62, 27, 8, 63, 18],\n",
    "    10: [41, 18, 19, 13, 6, 34, 10, 39, 0, 32, 52, 23, 55, 58, 5, 59],\n",
    "    17: [47, 59, 11, 54, 42, 25, 61, 45, 7, 20, 3, 49, 22, 51, 19, 46],\n",
    "    4: [11, 51, 29, 18, 31, 13, 53, 34, 39, 52, 20, 2, 6, 26, 21, 10, 60, 3, 30],\n",
    "    12: [41, 25, 14, 62, 10, 46, 26, 52, 4, 54, 23, 49, 16, 33, 30, 34, 53, 59, 63],\n",
    "    9: [5, 42, 21, 53, 60, 58, 24, 55, 50, 47, 43, 3, 37, 2, 33, 18, 29, 48, 62, 45, 38, 8, 22],\n",
    "    17: [52, 60, 20, 61, 14, 22, 26, 15, 25, 43, 5, 49, 19, 47, 46, 3, 27, 29],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78860266-6d81-48ef-9843-d49ed1bbdc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = glob.glob(os.path.join(outputDir, '*.npy'))\n",
    "print(f'Found {len(batches)}')\n",
    "total = 0\n",
    "allImages = []\n",
    "\n",
    "for batchIdx in selectedBatches.keys():\n",
    "    batch = np.load(batches[batchIdx])\n",
    "    selectedImgs = np.stack([batch[bIdx] for bIdx in selectedBatches[batchIdx]])\n",
    "    allImages.append(selectedImgs)\n",
    "    total += selectedImgs.shape[0]\n",
    "    print(selectedImgs.shape)\n",
    "    \n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b52e3b-d65e-478f-871a-6222bd6e2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "allBatches = np.concatenate(allImages)\n",
    "allBatches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62522d3b-51b4-43a9-99e9-107307d0f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = SimmimTransform(config)\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "masks = []\n",
    "losses = []\n",
    "\n",
    "for idx in range(allBatches.shape[0]):\n",
    "\n",
    "    image = allBatches[idx]\n",
    "\n",
    "    imgMasks = [transform(image)]\n",
    "\n",
    "    img = torch.stack([imgMask[0] for imgMask in imgMasks])\n",
    "    mask = torch.stack([torch.from_numpy(imgMask[1]) for imgMask in imgMasks])\n",
    "\n",
    "    img = img.cuda(non_blocking=True)\n",
    "    mask = mask.cuda(non_blocking=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with amp.autocast(enabled=config.ENABLE_AMP):\n",
    "            z = model.encoder(img, mask)\n",
    "            img_recon = model.decoder(z)\n",
    "            loss = model(img, mask)\n",
    "\n",
    "    inputs.extend(img.cpu())\n",
    "    masks.extend(mask.cpu())\n",
    "    outputs.extend(img_recon.cpu())\n",
    "    losses.append(loss.cpu()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d1ad8-b5c9-4efc-9bdd-9cd1b16e93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_export_pdf(path, inputs, outputs, masks, rgb_index):\n",
    "    pdf_plot_obj = PdfPages(path)\n",
    "\n",
    "    for idx in range(len(inputs)):\n",
    "        # prediction processing\n",
    "        image = inputs[idx]\n",
    "        img_recon = outputs[idx]\n",
    "        mask = masks[idx]\n",
    "        rgb_image, rgb_image_masked, rgb_recon_masked, mask = \\\n",
    "            process_prediction(image, img_recon, mask, rgb_index)\n",
    "\n",
    "        # matplotlib code\n",
    "        fig, (ax01, ax23) = plt.subplots(2, 2, figsize=(40, 30))\n",
    "        ax0, ax1 = ax01\n",
    "        ax2, ax3 = ax23\n",
    "        ax2.imshow(rgb_image)\n",
    "        ax2.set_title(f\"Idx: {idx} MOD021KM v6.1 Bands: {rgb_index}\")\n",
    "\n",
    "        ax0.imshow(rgb_recon_masked)\n",
    "        ax0.set_title(f\"Idx: {idx} Model reconstruction\")\n",
    "\n",
    "        ax1.imshow(rgb_image_masked)\n",
    "        ax1.set_title(f\"Idx: {idx} MOD021KM Bands: {rgb_index}, masked\")\n",
    "        \n",
    "        ax3.matshow(mask[:, :, 0])\n",
    "        ax3.set_title(f\"Idx: {idx} Reconstruction Mask\")\n",
    "        pdf_plot_obj.savefig()\n",
    "\n",
    "    pdf_plot_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac297b36-92bb-47d0-9f88-23f560586a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_export_pdf('satvision_toa_2m_224_patch16_128testchips_predictions.pdf', inputs, outputs, masks, rgb_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c272f-b035-4821-a520-fae9328485c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ilab-pytorch]",
   "language": "python",
   "name": "conda-env-ilab-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
